{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Preserving Text Structure\n\nWhen extracting text from documents, maintaining the original structure is crucial for downstream AI tasks. In this notebook, we'll learn how to preserve hierarchical structure from Markdown and HTML documents.\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n- Parse structured documents (Markdown, HTML) while preserving hierarchy\n- Extract metadata about document structure (headings, sections)\n- Create searchable document maps with table of contents\n- Handle structured data like tables within documents\n- Build section-based search functionality\n\n## Why Structure Matters\n\nPreserving text structure provides several benefits:\n- **Better chunking** - Respects semantic boundaries\n- **More accurate search** - Maintains context and hierarchy\n- **Improved Q&A** - Preserves relationships between sections\n- **Structured data handling** - Properly extracts tables and lists"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Parsing Markdown with Structure Preservation\n\nfrom llama_index.core.schema import Document\nfrom llama_index.core.node_parser import MarkdownNodeParser\nimport textwrap\n\n# Sample markdown document with clear hierarchical structure\nmarkdown_text = \"\"\"\n# AI Engineering Fundamentals\n\n## Introduction to Vector Databases\n\nVector databases are specialized database systems designed to store and query vector embeddings efficiently.\n\n### Key Advantages\n- Efficient similarity search\n- Scalable to billions of vectors\n- Support for metadata filtering\n\n### Common Operations\n1. **Vector Indexing**: Creating data structures for efficient search\n2. **Approximate Nearest Neighbor Search**: Finding similar vectors quickly\n3. **Hybrid Search**: Combining vector similarity with metadata filters\n\n## Working with Embeddings\n\nEmbeddings are dense numerical representations of data that capture semantic meaning.\n\n### Popular Embedding Models\n- OpenAI text-embedding-ada-002\n- Sentence Transformers\n- CLIP for image embeddings\n\"\"\"\n\n# Create a document\ndocument = Document(text=markdown_text)\n\n# Create a parser that recognizes markdown structure\nmarkdown_parser = MarkdownNodeParser()\n\n# Parse the document into structured nodes\nnodes = markdown_parser.get_nodes_from_documents([document])\n\n# Display the resulting nodes\nprint(f\"Markdown Parsing Results:\\n\")\nprint(\"=\" * 80)\nprint(f\"\\nTotal nodes created: {len(nodes)}\\n\")\n\nfor i, node in enumerate(nodes, 1):\n    print(f\"Node {i}:\")\n    print(f\"  Text: {textwrap.shorten(node.text, width=70)}...\")\n    print(f\"  Header path: {node.metadata.get('header_path', 'N/A')}\")\n    print()\n\nprint(\"✓ Markdown structure preserved with hierarchical metadata\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Parsing HTML with Structure Preservation\n\nfrom llama_index.core.node_parser import HTMLNodeParser\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n# Sample HTML document with headings, lists, and tables\nhtml_text = \"\"\"\n<html>\n<body>\n  <h1>AI Engineering Fundamentals</h1>\n  \n  <h2>Introduction to Vector Databases</h2>\n  <p>Vector databases are specialized database systems designed to store and query vector embeddings efficiently.</p>\n  \n  <h3>Key Advantages</h3>\n  <ul>\n    <li>Efficient similarity search</li>\n    <li>Scalable to billions of vectors</li>\n    <li>Support for metadata filtering</li>\n  </ul>\n  \n  <h3>Common Operations</h3>\n  <ol>\n    <li><b>Vector Indexing</b>: Creating data structures for efficient search</li>\n    <li><b>Approximate Nearest Neighbor Search</b>: Finding similar vectors quickly</li>\n    <li><b>Hybrid Search</b>: Combining vector similarity with metadata filters</li>\n  </ol>\n  \n  <h2>Working with Embeddings</h2>\n  <p>Embeddings are dense numerical representations of data that capture semantic meaning.</p>\n  \n  <table border=\"1\">\n    <tr>\n      <th>Model Name</th>\n      <th>Dimensions</th>\n      <th>Use Case</th>\n    </tr>\n    <tr>\n      <td>text-embedding-ada-002</td>\n      <td>1536</td>\n      <td>General text embeddings</td>\n    </tr>\n    <tr>\n      <td>all-MiniLM-L6-v2</td>\n      <td>384</td>\n      <td>Efficient semantic search</td>\n    </tr>\n  </table>\n</body>\n</html>\n\"\"\"\n\n# Create a document\nhtml_document = Document(text=html_text)\n\n# Create HTML parser\nhtml_parser = HTMLNodeParser()\n\n# Parse the document into nodes\nhtml_nodes = html_parser.get_nodes_from_documents([html_document])\n\n# Display parsing results\nprint(\"HTML Parsing Results:\\n\")\nprint(\"=\" * 80)\nprint(f\"\\nTotal HTML nodes created: {len(html_nodes)}\\n\")\n\nfor i, node in enumerate(html_nodes[:10], 1):  # Show first 10 nodes\n    tag = node.metadata.get('tag', 'N/A')\n    print(f\"Node {i} [{tag}]:\")\n    print(f\"  {textwrap.shorten(node.text, width=70)}...\")\n\nprint(f\"\\n... and {len(html_nodes) - 10} more nodes\")\n\n# Extract tables specifically\ndef extract_tables(html_content):\n    \"\"\"Extract table data from HTML\"\"\"\n    soup = BeautifulSoup(html_content, 'html.parser')\n    tables = soup.find_all('table')\n\n    extracted_tables = []\n    for table in tables:\n        rows = table.find_all('tr')\n        table_data = []\n\n        for row in rows:\n            cols = row.find_all(['td', 'th'])\n            row_data = [col.text.strip() for col in cols]\n            table_data.append(row_data)\n\n        extracted_tables.append(table_data)\n\n    return extracted_tables\n\n# Extract and display tables\ntables = extract_tables(html_text)\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Extracted Table:\\n\")\nfor row in tables[0]:\n    print(f\"  {row}\")\n\nprint(\"\\n✓ HTML structure preserved with tag metadata and table extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Creating a Searchable Document Map\n\ndef create_document_map(nodes):\n    \"\"\"\n    Create a searchable map of document sections.\n    \n    Args:\n        nodes: List of parsed document nodes\n        \n    Returns:\n        dict: Document map with section information\n    \"\"\"\n    document_map = {}\n\n    for i, node in enumerate(nodes):\n        # Get the heading or create a default one\n        heading = node.metadata.get(\"heading\", f\"Section {i+1}\")\n        level = node.metadata.get(\"heading_level\", 0)\n\n        # Add to document map with indent based on level\n        indent = \"  \" * (level - 1) if level > 0 else \"\"\n        document_map[heading] = {\n            \"index\": i,\n            \"level\": level,\n            \"text\": node.text,\n            \"display\": f\"{indent}{heading}\"\n        }\n\n    return document_map\n\ndef find_section(query, doc_map):\n    \"\"\"\n    Find sections that match a query string.\n    \n    Args:\n        query: Search term\n        doc_map: Document map to search\n        \n    Returns:\n        list: Matching sections with snippets\n    \"\"\"\n    matches = []\n\n    for heading, info in doc_map.items():\n        # Check if query is in heading or content\n        if query.lower() in heading.lower() or query.lower() in info['text'].lower():\n            matches.append((heading, info))\n\n    return matches\n\n# Create document map from markdown nodes\ndoc_map = create_document_map(nodes)\n\n# Display the document structure as a table of contents\nprint(\"Document Table of Contents:\\n\")\nprint(\"=\" * 80)\nfor heading, info in doc_map.items():\n    print(f\"  {info['display']}\")\n\n# Perform section-based searches\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Section-Based Search Examples:\\n\")\n\nsearch_terms = [\"advantages\", \"embedding models\", \"indexing\"]\n\nfor term in search_terms:\n    print(f\"Searching for '{term}':\")\n    results = find_section(term, doc_map)\n\n    if results:\n        for heading, info in results:\n            print(f\"  ✓ Found in: {info['display']}\")\n            \n            # Extract a relevant snippet\n            text = info['text']\n            term_pos = text.lower().find(term.lower())\n            if term_pos >= 0:\n                start = max(0, term_pos - 40)\n                snippet = text[start:start+100].strip() + \"...\"\n                print(f\"    Snippet: {snippet}\")\n    else:\n        print(f\"  ✗ No results found\")\n    print()\n\nprint(\"✓ Document map enables efficient section-based navigation and search\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\nWe've explored how to preserve and leverage document structure during text extraction:\n\n### Key Techniques\n\n1. **Markdown Parsing** - MarkdownNodeParser preserves:\n   - Heading hierarchy (H1, H2, H3)\n   - Header paths showing document structure\n   - Section relationships\n\n2. **HTML Parsing** - HTMLNodeParser preserves:\n   - Tag information (headings, paragraphs, lists)\n   - Structured data (tables, lists)\n   - Document hierarchy\n\n3. **Document Maps** - Create searchable structures with:\n   - Table of contents generation\n   - Section-based navigation\n   - Hierarchical search\n\n4. **Table Extraction** - BeautifulSoup enables:\n   - Structured table data extraction\n   - Conversion to usable formats\n   - Integration with other parsers\n\n### Benefits of Structure Preservation\n\n- **Better retrieval** - Search respects document hierarchy\n- **Context preservation** - Maintains relationships between sections\n- **Improved chunking** - Creates semantically meaningful chunks\n- **Enhanced metadata** - Richer information for downstream tasks\n\n### Best Practices\n\n- Use structure-aware parsers (Markdown, HTML) when possible\n- Preserve header paths and hierarchy metadata\n- Extract tables and structured data separately when needed\n- Build document maps for navigation and search\n- Maintain section context in your chunks\n\nStructure-aware parsing enables more sophisticated AI applications that understand document organization, not just raw text.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}